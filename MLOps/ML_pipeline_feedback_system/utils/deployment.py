"""KServe ëª¨ë¸ ë°°í¬ ìœ í‹¸ë¦¬í‹°"""

import yaml
import json
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

from google.cloud import storage


class DeploymentConfig:
    def __init__(self, config_path: str = None):
        if config_path is None:
            current_dir = Path(__file__).parent.parent
            config_path = current_dir / 'config' / 'deploy.yaml'

        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

    def get_site_config(self, site_id: str) -> Dict[str, Any]:
        if site_id not in self.config['sites']:
            raise ValueError(f"Site '{site_id}' not found in deploy.yaml")
        return self.config['sites'][site_id]

    def get_gcs_bucket(self) -> str:
        return self.config['gcs']['bucket_name']


class ModelDeployment:
    def __init__(self, site_id: str, config_path: str = None):
        self.site_id = site_id
        self.config = DeploymentConfig(config_path) if config_path else DeploymentConfig()
        self.site_config = self.config.get_site_config(site_id)
        self.bucket_name = self.config.get_gcs_bucket()

        # GCS í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        from google.oauth2 import service_account
        import os

        # credentials_pathë¥¼ configì—ì„œ ì½ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
        credentials_path = self.config.config['gcs'].get('credentials_path')
        if not credentials_path:
            credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS', '/path/to/credentials.json')

        credentials = service_account.Credentials.from_service_account_file(credentials_path)
        gcp_project = os.getenv('GCP_PROJECT', 'your-gcp-project')
        self.storage_client = storage.Client(credentials=credentials, project=gcp_project)
        self.bucket = self.storage_client.bucket(self.bucket_name)

    def promote_to_production(self, model_version: str, deploy_decision: Dict[str, Any]) -> Dict[str, Any]:
        if not deploy_decision.get('deploy', False):
            print("âŒ ë°°í¬ ì¡°ê±´ ë¯¸ì¶©ì¡± - ê±´ë„ˆëœ€")
            return None

        paths = self.site_config['paths']
        deploy_files = self.site_config['deploy_files']

        source_model_path = f"{paths['models_dir']}/{model_version}/{model_version}_xgboost_{self.site_id}_model.pkl"
        source_params_path = f"{paths['models_dir']}/{model_version}/{model_version}_xgboost_{self.site_id}.json"

        deploy_model_path = f"{paths['deploy_dir']}/{deploy_files['model']}"
        deploy_params_path = f"{paths['deploy_dir']}/{deploy_files['hyperparameters']}"
        deploy_metadata_path = f"{paths['deploy_dir']}/{deploy_files['metadata']}"

        print(f"\n{'='*60}")
        print(f"ëª¨ë¸ ë°°í¬ ì‹œì‘: {self.site_id}")
        print(f"{'='*60}")
        print(f"\nğŸš€ ìƒˆ ëª¨ë¸ ë°°í¬ ì¤‘...")
        print(f"  ì›ë³¸: gs://{self.bucket_name}/{source_model_path}")
        print(f"  ëŒ€ìƒ: gs://{self.bucket_name}/{deploy_model_path}")

        source_model_blob = self.bucket.blob(source_model_path)
        self.bucket.copy_blob(source_model_blob, self.bucket, deploy_model_path)

        source_params_blob = self.bucket.blob(source_params_path)
        self.bucket.copy_blob(source_params_blob, self.bucket, deploy_params_path)

        metadata = {
            'site_id': self.site_id,
            'model_version': model_version,
            'deployed_at': datetime.now().isoformat(),
            'source_model_path': f'gs://{self.bucket_name}/{source_model_path}',
            'deploy_model_path': f'gs://{self.bucket_name}/{deploy_model_path}',
            'metrics': deploy_decision.get('new_metrics', {}),
            'improvement_over_previous': deploy_decision.get('improvement', {}),
            'deployment_method': 'automatic',
            'kserve_endpoint': self.site_config['kserve']['endpoint'],
            'namespace': self.site_config['namespace']
        }

        metadata_blob = self.bucket.blob(deploy_metadata_path)
        metadata_blob.upload_from_string(
            json.dumps(metadata, indent=2, ensure_ascii=False),
            content_type='application/json'
        )

        print(f"  âœ“ ëª¨ë¸ ë°°í¬ ì™„ë£Œ!")
        print(f"\nğŸ“Š ë°°í¬ ì •ë³´:")
        print(f"  - ëª¨ë¸ ë²„ì „: {model_version}")
        print(f"  - ë°°í¬ ì‹œê°„: {metadata['deployed_at']}")

        return metadata

    def get_deployment_history_from_gcs(self) -> Dict[str, Any]:
        paths = self.site_config['paths']
        deploy_files = self.site_config['deploy_files']

        history_path = f"{paths['deploy_dir']}/{deploy_files['deployment_history']}"
        history_blob = self.bucket.blob(history_path)

        if history_blob.exists():
            return json.loads(history_blob.download_as_string())
        else:
            return {
                'site_id': self.site_id,
                'created_at': datetime.now().isoformat(),
                'deployments': []
            }

    def save_deployment_history_to_gcs(self, history: Dict[str, Any]) -> None:
        paths = self.site_config['paths']
        deploy_files = self.site_config['deploy_files']

        history_path = f"{paths['deploy_dir']}/{deploy_files['deployment_history']}"
        history_blob = self.bucket.blob(history_path)

        history['last_updated'] = datetime.now().isoformat()
        history['total_deployments'] = len(history['deployments'])

        history_blob.upload_from_string(
            json.dumps(history, indent=2, ensure_ascii=False),
            content_type='application/json'
        )

        print(f"\nğŸ“ ë°°í¬ ì´ë ¥ ì €ì¥ ì™„ë£Œ: gs://{self.bucket_name}/{history_path}")

    def record_deployment(self, metadata: Dict[str, Any]) -> str:
        history = self.get_deployment_history_from_gcs()

        deployment_record = {
            'deployment_id': f"{self.site_id}_{metadata['model_version']}_{int(datetime.now().timestamp())}",
            'model_version': metadata['model_version'],
            'deployed_at': metadata['deployed_at'],
            'source_model_path': metadata['source_model_path'],
            'metrics': metadata['metrics'],
            'improvement': metadata.get('improvement_over_previous', {}),
            'deployment_method': metadata['deployment_method'],
            'status': 'active',
            'kserve_endpoint': metadata['kserve_endpoint']
        }

        history['deployments'].insert(0, deployment_record)
        self.save_deployment_history_to_gcs(history)

        print(f"\nâœ… ë°°í¬ ì´ë ¥ ê¸°ë¡ ì™„ë£Œ - {deployment_record['deployment_id']}")

        return deployment_record['deployment_id']


def promote_model_to_production(**context):
    import os
    ti = context['task_instance']
    execution_date = context['execution_date']

    site_id = context['dag'].tags[0] if context['dag'].tags else os.getenv('SITE_ID', 'default_site')
    model_version = execution_date.strftime('%Y%m')

    deploy_decision = ti.xcom_pull(key='deploy_decision', task_ids='validate_model')

    deployment = ModelDeployment(site_id)
    metadata = deployment.promote_to_production(model_version, deploy_decision)

    if metadata:
        ti.xcom_push(key='deployment_metadata', value=metadata)
        return metadata
    else:
        return None


def record_deployment_to_gcs(**context):
    ti = context['task_instance']
    metadata = ti.xcom_pull(key='deployment_metadata', task_ids='promote_to_production')

    if not metadata:
        print("ë°°í¬ëœ ëª¨ë¸ì´ ì—†ìŒ - ë°°í¬ ì´ë ¥ ê¸°ë¡ ê±´ë„ˆëœ€")
        return None

    deployment = ModelDeployment(metadata['site_id'])
    deployment_id = deployment.record_deployment(metadata)

    ti.xcom_push(key='deployment_id', value=deployment_id)
    return {'deployment_id': deployment_id}


def trigger_kserve_reload(**context):
    ti = context['task_instance']
    metadata = ti.xcom_pull(key='deployment_metadata', task_ids='promote_to_production')

    if not metadata:
        print("ë°°í¬ëœ ëª¨ë¸ ì—†ìŒ - KServe ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€")
        return False

    site_id = metadata['site_id']
    model_version = metadata['model_version']
    namespace = metadata['namespace']

    config = DeploymentConfig()
    site_config = config.get_site_config(site_id)
    inference_service_name = site_config['kserve']['inference_service_name']

    print(f"\n{'='*60}")
    print(f"KServe InferenceService ì—…ë°ì´íŠ¸ (SSH ì›ê²© ì‹¤í–‰)")
    print(f"{'='*60}")
    print(f"  Service: {inference_service_name}")
    print(f"  Namespace: {namespace}")
    print(f"  ëª¨ë¸ ë²„ì „: {model_version}")

    # SSH ì ‘ì† ì •ë³´ ë¡œë“œ (.env íŒŒì¼ì—ì„œ)
    from pathlib import Path
    import os
    from dotenv import load_dotenv

    config_dir = Path(__file__).parent.parent / 'config'
    env_path = config_dir / '.env'
    load_dotenv(env_path)

    ssh_host = os.getenv('SSH_HOST')
    ssh_port = os.getenv('SSH_PORT')
    ssh_user = os.getenv('SSH_USER')
    ssh_password = os.getenv('SSH_PASSWORD')

    if not all([ssh_host, ssh_port, ssh_user, ssh_password]):
        raise ValueError("SSH ì ‘ì† ì •ë³´ê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤ (SSH_HOST, SSH_PORT, SSH_USER, SSH_PASSWORD)")

    print(f"\nğŸ” SSH ì—°ê²° ì •ë³´:")
    print(f"  Host: {ssh_user}@{ssh_host}:{ssh_port}")

    annotations = [
        f'deployment.info/model-version={model_version}',
        f'deployment.info/last-updated={datetime.now().isoformat()}',
        f'deployment.info/source-path={metadata["source_model_path"]}'
    ]

    # kubectl ëª…ë ¹ì–´ ìƒì„± (sudo su í›„ ì‹¤í–‰)
    kubectl_annotate_cmd = (
        f"kubectl annotate inferenceservice {inference_service_name} "
        f"-n {namespace} --overwrite "
        f"{' '.join(annotations)}"
    )

    kubectl_wait_cmd = (
        f"kubectl rollout status deployment "
        f"-n {namespace} "
        f"-l serving.kserve.io/inferenceservice={inference_service_name} "
        f"--timeout=5m"
    )

    kubectl_restart_cmd = (
        f"kubectl rollout restart deployment "
        f"-n {namespace} "
        f"-l serving.kserve.io/inferenceservice={inference_service_name}"
    )

    # paramiko importë¥¼ í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ìœ¼ë¡œ ì´ë™
    import paramiko

    def run_sudo_command(ssh_client, command, timeout=60):
        """
        sudo su í›„ kubectl ëª…ë ¹ì–´ ì‹¤í–‰

        Args:
            ssh_client: paramiko SSH í´ë¼ì´ì–¸íŠ¸
            command: ì‹¤í–‰í•  kubectl ëª…ë ¹ì–´
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

        Returns:
            tuple: (exit_code, stdout, stderr)
        """
        # sudo su -c ë¥¼ ì‚¬ìš©í•˜ì—¬ root ê¶Œí•œìœ¼ë¡œ ëª…ë ¹ ì‹¤í–‰
        # ë¹„ë°€ë²ˆí˜¸ëŠ” echoë¡œ ì „ë‹¬
        sudo_cmd = f"echo '{ssh_password}' | sudo -S su -c \"{command}\""

        stdin, stdout, stderr = ssh_client.exec_command(sudo_cmd, timeout=timeout)
        exit_code = stdout.channel.recv_exit_status()
        stdout_text = stdout.read().decode('utf-8')
        stderr_text = stderr.read().decode('utf-8')

        # sudo ë¹„ë°€ë²ˆí˜¸ í”„ë¡¬í”„íŠ¸ ì œê±°
        stderr_text = '\n'.join([
            line for line in stderr_text.split('\n')
            if 'sudo' not in line.lower() and 'password' not in line.lower()
        ]).strip()

        return exit_code, stdout_text, stderr_text

    try:
        # SSH í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        print(f"\nğŸ”Œ SSH ì—°ê²° ì¤‘...")
        ssh_client.connect(
            hostname=ssh_host,
            port=int(ssh_port),
            username=ssh_user,
            password=ssh_password,
            timeout=30
        )
        print(f"  âœ“ SSH ì—°ê²° ì„±ê³µ")

        # 1. Annotation ì—…ë°ì´íŠ¸
        print(f"\nğŸ“ Annotation ì—…ë°ì´íŠ¸ ì¤‘ (sudo su)...")
        print(f"  ëª…ë ¹ì–´: {kubectl_annotate_cmd}")

        exit_code, stdout_text, stderr_text = run_sudo_command(
            ssh_client, kubectl_annotate_cmd, timeout=60
        )

        if exit_code == 0:
            print(f"  âœ“ Annotation ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            if stdout_text:
                print(stdout_text)
        else:
            print(f"  âŒ Annotation ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {stderr_text}")
            raise Exception(f"kubectl annotate ì‹¤íŒ¨: {stderr_text}")

        # 2. Rolling Update ëŒ€ê¸°
        print(f"\nâ³ Rolling update ëŒ€ê¸° ì¤‘ (ìµœëŒ€ 5ë¶„, sudo su)...")

        exit_code, stdout_text, stderr_text = run_sudo_command(
            ssh_client, kubectl_wait_cmd, timeout=320
        )

        if exit_code == 0:
            print(f"  âœ“ Rolling update ì™„ë£Œ")
            if stdout_text:
                print(stdout_text)
            ssh_client.close()

            ti.xcom_push(key='kserve_reload_success', value=True)
            return True
        else:
            print(f"  âš ï¸ Rolling update ëŒ€ê¸° ì‹¤íŒ¨, Pod ì¬ì‹œì‘ ì‹œë„")
            print(f"  ì˜¤ë¥˜: {stderr_text}")

    except Exception as e:
        print(f"\nâš ï¸ Annotation ë°©ì‹ ì‹¤íŒ¨: {e}")
        print(f"  ëŒ€ì²´ ë°©ë²• ì‹œë„: Pod ì¬ì‹œì‘")

    # ëŒ€ì²´ ë°©ë²•: Pod ì¬ì‹œì‘
    try:
        if 'ssh_client' not in locals() or ssh_client.get_transport() is None:
            ssh_client = paramiko.SSHClient()
            ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh_client.connect(
                hostname=ssh_host,
                port=int(ssh_port),
                username=ssh_user,
                password=ssh_password,
                timeout=30
            )

        print(f"\nğŸ”„ Pod ì¬ì‹œì‘ ì¤‘ (sudo su)...")
        print(f"  ëª…ë ¹ì–´: {kubectl_restart_cmd}")

        exit_code, stdout_text, stderr_text = run_sudo_command(
            ssh_client, kubectl_restart_cmd, timeout=60
        )

        if exit_code == 0:
            print(f"  âœ“ Pod ì¬ì‹œì‘ ì™„ë£Œ")
            if stdout_text:
                print(stdout_text)
            ssh_client.close()

            ti.xcom_push(key='kserve_reload_success', value=True)
            return True
        else:
            print(f"  âŒ Pod ì¬ì‹œì‘ ì‹¤íŒ¨: {stderr_text}")
            ssh_client.close()

            ti.xcom_push(key='kserve_reload_success', value=False)
            raise Exception(f"kubectl rollout restart ì‹¤íŒ¨: {stderr_text}")

    except Exception as e:
        print(f"âŒ ëª¨ë“  ë°©ë²• ì‹¤íŒ¨: {e}")
        if 'ssh_client' in locals():
            ssh_client.close()

        ti.xcom_push(key='kserve_reload_success', value=False)
        raise


def get_deployment_history(site_id: str = 'default_site', limit: int = 10):
    deployment = ModelDeployment(site_id)
    history = deployment.get_deployment_history_from_gcs()

    print(f"\n{'='*60}")
    print(f"{site_id} ë°°í¬ ì´ë ¥")
    print(f"{'='*60}")
    print(f"ì´ ë°°í¬ íšŸìˆ˜: {history.get('total_deployments', 0)}\n")

    for i, record in enumerate(history['deployments'][:limit], 1):
        print(f"{i}. ë²„ì „: {record['model_version']}")
        print(f"   ë°°í¬ ì‹œê°„: {record['deployed_at']}")
        print(f"   ì„±ëŠ¥: {record['metrics']}")
        print()

    return history
